<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 7.5.1.2 (Windows)"/>
	<meta name="created" content="00:00:00"/>
	<meta name="changed" content="2023-04-24T11:50:50.597000000"/>
	<style type="text/css">
		td p { color: #000000; font-family: "Arial"; font-size: 11pt }
		h1 { color: #000000; font-family: "Arial"; font-size: 20pt; line-height: 114%; text-align: left; orphans: 2; widows: 2; border: none; padding: 0cm }
		p { color: #000000; font-family: "Arial"; font-size: 11pt }
		h2 { color: #000000; font-family: "Arial"; font-size: 16pt; line-height: 114%; text-align: left; orphans: 2; widows: 2; border: none; padding: 0cm }
		h4 { color: #666666; font-family: "Arial"; line-height: 114%; text-align: left; orphans: 2; widows: 2; border: none; padding: 0cm }
	</style>
</head>
<body lang="en-GB" dir="ltr"><h1>Interdisciplinary Perspectives on
Technologies for Mingling</h1>
<h4><a name="h.tmptoux9f1tn"></a>The Future of Conversations and
Mingling 
</h4>
<p>Time: 2 May 2023</p>
<p>Location : &nbsp;<a href="https://www.google.com/url?q=https://vakwerkhuis.com/&amp;sa=D&amp;source=editors&amp;ust=1682333342477159&amp;usg=AOvVaw294wqjY9OPYnZPdAY0VYtM">Vakwerkhuis,
Delft </a>
</p>
<p style="margin-bottom: 0cm"><span style="display: inline-block; border: 1px solid #000000; padding: 0.05cm"><img src="images/image1.png" name="Image1" align="bottom" width="538" height="303" border="0"/>
</span></p>
<p><a name="h.bf7z376z34o6"></a><a href="#h.uobv7junyb4f">Registration
and Participation:</a></p>
<p><a href="#h.gg8m22e8uqaw">Introduction</a></p>
<p><a href="#h.l3c9d5n4e4o4">Motivation</a></p>
<p><a href="#h.og4jawi1xhf5">Bring your posters!</a></p>
<p><a href="#h.5rwur0w63m4d">Schedule</a></p>
<p><a href="#h.2gbt7c8ah9zb">Invited Talks</a></p>
<p><a href="#h.35tfy9xgnrgx">MINGLE Project Talks</a></p>
<p><a href="#h.r0r4rnwmcv0z">Poster Presentations</a></p>
<h2><a name="h.4pwtykwvsx7b"></a><a name="h.uobv7junyb4f"></a>Registration
and Participation: 
</h2>
<p>Please register <a href="https://www.google.com/url?q=https://docs.google.com/forms/d/e/1FAIpQLSdii11cRmcQ9Y-fJQTgnAI8FK64ngxShm0_I27oHdR8tEsXLQ/viewform&amp;sa=D&amp;source=editors&amp;ust=1682333342479554&amp;usg=AOvVaw3OXfOSQvrGJVRsmRh5o_cY">here
</a>before April 25. The main idea is to use this as a networking and
idea exchange opportunity so registration is free!</p>
<p>The main aim of this event is to bring together researchers and
stakeholders who may not have become united by such a common theme
before. So physical presence is strongly encouraged. However, if you
would like to join remotely, here is the link:</p>
<p>Join Zoom Meeting</p>
<p><a href="https://www.google.com/url?q=https://tudelft.zoom.us/j/97141920397?pwd%3DamxlMmR1d244b0piT0c0MnpXRXAxZz09&amp;sa=D&amp;source=editors&amp;ust=1682333342480355&amp;usg=AOvVaw1FTA92WUREtGXmJC8hY9-u">https://tudelft.zoom.us/j/97141920397?pwd=amxlMmR1d244b0piT0c0MnpXRXAxZz09</a></p>
<p>Meeting ID: 971 4192 0397</p>
<p>Passcode: 661783</p>
<h2><a name="h.gg8m22e8uqaw"></a>Introduction</h2>
<p>Attending social networking events has been correlated with career
success. Yet little is known about how or why they function well or
how we could make them more useful for us. This is despite the fact
that we spend substantial time and money to attend them. One of the
major bottlenecks has been related to difficulties in observing such
behaviour systematically. This has made it hard to develop theories
to fully understand what happens in these crowds. Without the
possibility to analyse them, technologies cannot be built to help us
to make the most out of these experiences which can sometimes be
anxiety inducing for some. 
</p>
<p>During the global pandemic of recent years, these spontaneous
moments of conversational interaction were lost and led to people
questioning whether we should bring serendipity and spontaneity back
in other forms. What makes a conversation good? What makes them
interesting enough to form new bonds or foster existing connections?
How does this play out in groups? 
</p>
<p>This symposium aims to crack open the mysteries of mingling
behaviour from multiple different perspectives. Moreover,
understanding how to build technologies for such settings would
enable us to bridge the gap in understanding behaviours in similar
and even more commonplace activities such as the role of spontaneous
discussions by the coffee machine at work or in public spaces. 
</p>
<h2><a name="h.l3c9d5n4e4o4"></a>Motivation</h2>
<p>The day aims to present an overarching view of the research
results of the NWO funded Vidi project MINGLE (Modelling Social Group
Dynamics and Interaction Quality in Complex Scenes using Multi-Sensor
Analysis of Non-Verbal Behaviour). Whilst this is the closing event
of the MINGLE project, it is also aimed as a new beginning. The
research results of MINGLE will feed into a new ERC Consolidator
grant funded project NEON (Nonverbal Intention Modelling) which will
focus on the analysis of intention, particularly &nbsp;in mingling
settings. So we are looking for new perspectives to enrich the new
research journey.</p>
<p>Since this is a first of its kind event, we want to kickstart a
new kind of community that explores important research questions,
solutions, and needs that can aid spontaneous social connection
making. 
</p>
<h2><a name="h.og4jawi1xhf5"></a>Bring your posters!</h2>
<p>Do you work on a related&nbsp;topic? topics include but are not
limited to:</p>
<ul>
	<li><p style="margin-bottom: 0cm">Individual and Social
	Behaviour&nbsp;Understanding (e.g. gaze, gestures, postures, speech
	detection, paralinguistics, multimodal behaviour analysis)</p>
	<li><p style="margin-bottom: 0cm">Cognitive states (e.g. affect,
	memory, trust)</p>
	<li><p style="margin-bottom: 0cm">Cooperation and Collaboration in
	groups, organizations</p>
	<li><p style="margin-bottom: 0cm">Interpersonal factors: engagement,
	rapport, synchrony, and mimicry</p>
	<li><p style="margin-bottom: 0cm">Ethics and Privacy issues</p>
	<li><p style="margin-bottom: 0cm">Interactive agents (e.g. social
	robots, virtual agents)</p>
	<li><p style="margin-bottom: 0cm">Wearable/ubiquitous sensing</p>
	<li><p style="margin-bottom: 0cm">Data collection techniques</p>
	<li><p style="margin-bottom: 0cm">Data annotation techniques</p>
	<li><p>Technologies to enable or enhance social interactions</p>
</ul>
<h2><a name="h.5rwur0w63m4d"></a>Schedule 
</h2>
<p>Please note the schedule is not yet finalised and may be subject
to slight shifts!</p><a name="t.ee56856513e9432565079eac73e763e8f7c61da8"></a><a name="t.0"></a>
<table cellpadding="2" cellspacing="2">
	<thead>
		<tr>
			<td style="border: none; padding: 0cm"><p>Time</p>
			</td>
			<td style="border: none; padding: 0cm"></td>
			<td style="border: none; padding: 0cm"><p>Speaker</p>
			</td>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td style="border: none; padding: 0cm"><p>9:15</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Walk in: tea, coffee,
				and refreshments are available</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chair: Chirag Raman</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>9:45</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Opening</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Hayley Hung 
				</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>10:00</p>
			</td>
			<td style="border: none; padding: 0cm"><p><a href="#h.ni0z9p3anb89">Head
				and Body behaviour Estimation with F-formations</a></p>
			</td>
			<td style="border: none; padding: 0cm"><p>Stephanie Tan</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>10:20</p>
			</td>
			<td style="border: none; padding: 0cm"><p><a href="#h.xwayb5vb9b6j">Studies
				on Social Interaction using Wearables and Theatre</a></p>
			</td>
			<td style="border: none; padding: 0cm"><p>Jamie A Ward</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>10:55</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Coffee Break/ hang
				poster</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chair: Hayley Hung</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>11:10</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Data Collection and
				Annotation of Complex Conversational Scenes</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Jose Vargas Quiros and
				&nbsp;Chirag Raman</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>11:30</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Talk Title: TBA</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Jean-Marc Odobez</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>12:05</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Buffet Lunch</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chair: Hayley Hung</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>13:05</p>
			</td>
			<td style="border: none; padding: 0cm"><p><a href="#h.yi04rxhqk484">Robots
				within Groups of People</a></p>
			</td>
			<td style="border: none; padding: 0cm"><p>Xavier Alameda Pineda</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>13:40</p>
			</td>
			<td style="border: none; padding: 0cm"><p>F-formation Modelling
				and Behavioural Cue Forecasting.</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chirag Raman</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>14:00</p>
			</td>
			<td style="border: none; padding: 0cm"><p><a href="#h.7q9szsni17p9">Socially
				significant bodily rhythms</a></p>
			</td>
			<td style="border: none; padding: 0cm"><p>Wim Pouw</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>14:35</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Coffee Break</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chair: Bernd Dudzik</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>14:50</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Estimating
				Conversational Enjoyment and Learning Multiple Truths about
				Laughter</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chirag Raman and Hayley
				Hung</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>15:10</p>
			</td>
			<td style="border: none; padding: 0cm"><p><a href="#h.gkwxxgl0hets">Understanding
				Expertise Search Strategies at Networking Events: &nbsp;An
				Exploratory Study Using Sociometric Badges</a></p>
			</td>
			<td style="border: none; padding: 0cm"><p>Balint Dioszegi</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>15:45</p>
			</td>
			<td style="border: none; padding: 0cm"><p>The ConfFlow
				Application: Encouraging New Diverse Collaborations by Helping
				Researchers Find Each Other at a Conference</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Hayley Hung</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>15:50</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Coffee Break</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Chair: Bernd Dudzik</p>
			</td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>16:05</p>
			</td>
			<td style="border: none; padding: 0cm"><p>(Panel) Discussion: &nbsp;The
				main aim of this discussion is to reflect on the talks of the day
				and to discuss how to build technologies and carry out research
				to support spontaneous interactions</p>
			</td>
			<td style="border: none; padding: 0cm"></td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>17.10</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Drinks reception and
				poster session</p>
			</td>
			<td style="border: none; padding: 0cm"></td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>18:15</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Group walk to the dinner
				location</p>
			</td>
			<td style="border: none; padding: 0cm"></td>
		</tr>
		<tr>
			<td style="border: none; padding: 0cm"><p>18:30 
				</p>
			</td>
			<td style="border: none; padding: 0cm"><p>Dinner in town <a href="https://www.google.com/url?q=https://huszar.nl/en/&amp;sa=D&amp;source=editors&amp;ust=1682333342502720&amp;usg=AOvVaw0TFTZyh765cPlEWOSTJkfY">(Huszar</a>)
				located 5 minutes from Delft Central Station and a 15 minute walk
				from Vakwerkhuis.</p>
			</td>
			<td style="border: none; padding: 0cm"></td>
		</tr>
	</tbody>
</table>
<h4><a name="h.svdn3qvno0ni"></a>PhD Thesis Defense of Stephanie Tan
on May 3</h4>
<p>The PhD thesis defense of Stephanie Tan will start at 9.30
(layman’s presentation) before the defense at 10am in the Aula on
the campus of TUDelft.</p>
<h2><a name="h.2gbt7c8ah9zb"></a>Invited Talks</h2>
<h4><a name="h.xwayb5vb9b6j"></a>Talk Title:&nbsp;Studies on Social
Interaction using Wearables and Theatre<br/>
Speaker: &nbsp;Dr Jamie
A Ward, Senior Lecturer in Computer Science at Goldsmiths University
of London</h4>
<p>Abstract: Measuring detailed information on how people move, see,
and think during realistic social situations can be a powerful method
in studying social behaviour and cognition. However,
&nbsp;measurement-driven research can be limited by the available
technology, &nbsp;with bulky equipment and rigid constraints often
confining such work to the laboratory, thus limiting the ecological
validity of any findings. &nbsp;Together with colleagues at
Goldsmiths, UCL, and Keio University, I have been working on several
projects that use wearable sensing to take this research out of the
laboratory and into the real world -- while on the way, stopping off
at the theatre. In this talk, I will give a brief overview of some of
our work, and try to show how the paradigm of &nbsp;'theatre as a
laboratory', might provide a way forward, both for &nbsp;research in
social cognition, and in wearable sensing.</p>
<h4><a name="h.yi04rxhqk484"></a>Talk Title:&nbsp;Robots within
Groups of People<br/>
Speaker: &nbsp;<a href="https://www.google.com/url?q=http://xavirema.eu/&amp;sa=D&amp;source=editors&amp;ust=1682333342504612&amp;usg=AOvVaw1EVsncwDvsCV_I5kVCC7y2">Xavier
Alameda-Pineda</a>, INRIA, France</h4>
<p>Abstract: One of the prominent applications of understanding
social human behavior is the development of systems that can
interpret, react to, and synthesize behavioral cues, and therefore
take and be part of social interactions. In this very general
context, social autonomous systems, e.g. social robotics, are a very
challenging and complex research area that has received increasing
attention over the past years. In this talk, I will be discussing the
conception of machine learning methods allowing to perceive, generate
and synthesize certain human behavioral cues. The tackled tasks will
range from speech enhancement to meta-training for social navigation,
and for each of them I will focus on one technical detail that is
crucial for the conception of the machine learning model and
associated training algorithm.</p>
<h4><a name="h.gkwxxgl0hets"></a>Talk Title:&nbsp;Understanding
Expertise Search Strategies at Networking Events: &nbsp;An
Exploratory Study Using Sociometric Badges<br/>
Speaker: <a href="https://www.google.com/url?q=https://www.linkedin.com/in/b%25C3%25A1lint-di%25C3%25B3szegi-8292734b/?originalSubdomain%3Duk&amp;sa=D&amp;source=editors&amp;ust=1682333342505404&amp;usg=AOvVaw1OdsjbL05guykSnjg0cx8F">Balint
Dioszegi</a>, University of Greenwich, UK</h4>
<p>Abstract: In this study we ask how individuals search for experts
at networking events. Building on the intuition that individuals’
propensities to engage in certain search actions, as well as their
effectiveness in locating experts, will depend on the quality and
salience of the metaknowledge they have about others, we conducted an
expert search game as a field experiment in which we randomly
assigned participants – researchers in a multinational corporation
– to one of three treatment conditions, reflecting varying degrees
of search planning. Based on data from sociometric badges, we derive
a taxonomy of the micro-decisions individuals make at events. We find
that letting others approach yields more referrals than taking the
initiative in starting conversations, and that planning increases the
tendency to maintain such initiative even when doing so is
ineffective – a possible manifestation of the Einstellung effect.</p>
<h4><a name="h.on2dthapwzsb"></a>Talk Title:&nbsp;TBA<br/>
Speaker:
<a href="https://www.google.com/url?q=https://www.idiap.ch/~odobez/&amp;sa=D&amp;source=editors&amp;ust=1682333342506092&amp;usg=AOvVaw0NxT7S9_saRHtSlROnpXy4">Jean-Marc
Odobez</a>, Idiap Research Institute and EPFL, Switzerland</h4>
<p>Abstract: TBA</p>
<h4><a name="h.7q9szsni17p9"></a>Talk Title:&nbsp;Socially
significant bodily rhythms<br/>
Speaker: <a href="https://www.google.com/url?q=https://wimpouw.com/&amp;sa=D&amp;source=editors&amp;ust=1682333342506732&amp;usg=AOvVaw0w0ZDZD71JYEg-wCH3OPSh">Wim
Pouw</a>, Radboud University, Netherlands</h4>
<p>Abstract: TBA</p>
<h2><a name="h.35tfy9xgnrgx"></a>MINGLE Project Talks</h2>
<h4><a name="h.ni0z9p3anb89"></a>Talk Title: Head and Body behaviour
Estimation with F-formations<br/>
Speaker: &nbsp;Stephanie Tan</h4>
<p>Abstract: 
</p>
<p>In recent years, new domains such as social signal processing and
social computing have emerged at the intersection of computer
science, human behavioral modeling, and robotics. The aim of these
fields is to achieve machine perception of social intelligence, such
as understanding behavioral cues of humans (e.g., body language) and
complex social relations and attitudes (e.g., dominance, rapport).
Challenges towards building such systems include data acquisition
with appropriate sensing capabilities for capturing in-the-wild human
data, as well as modelling approaches that account for data from
multiple modalities (vision, audio, motion) and address
context-awareness. In light of these challenges, I will present my
work on (1) head and body orientation estimation using sparse weak
labels from wearable sensors, (2) joint head orientation estimation
in conversation groups, and (3) conversation group detection in
social interaction scenes, in addition to an overview on the related
data-oriented contributions. I motivate these three tasks from the
perspective of individual-level, group-level, and scene-level
behavior understanding, and conclude with some open questions related
to automated analysis of social behaviors. &nbsp;</p>
<p>Associated Paper(s):</p>
<p>S. Tan, D. M. J. Tax, H. Hung, Conversation group detection with
spatio-temporal context,Proceedings of 2022 International Conference
on Multimedia (ICMI) (2022), Pages 170–180, Oral Presentation</p>
<p>S. Tan, D. M. J. Tax, H. Hung, Multimodal joint head orientation
estimation in interacting groups via proxemics and interaction
dynamics, Proceedings of the ACM on Interactive, Mobile, Wearable and
Ubiquitous Technologies (IMWUT) (2021), Vol.5, No.1, 1-22.</p>
<p>S. Tan, D. M. J. Tax, H. Hung, Head and body orientation
estimation with sparse weak labels in free standing conversational
settings, Understanding Social Behavior in Dyadic and Small Group
Interactions, Proceedings of Machine Learning Research (2021),
179-203. Presented at ICCV 2021 Understanding Social Behavior in
Dyadic and Small Group Interactions Workshop</p>
<h4><a name="h.e5sevkx583y9"></a>Talk Title:Data Collection and
Annotation of Complex Conversational Scenes<br/>
Speaker: &nbsp;Jose
Vargas Quiros and Chirag Raman</h4>
<p>Abstract:</p>
<p>Associated Paper(s):</p>
<p>Quiros, J. V., Tan, S., Raman, C., Cabrera-Quiros, L., &amp; Hung,
H. (2022, March). Covfee: an extensible web framework for
continuous-time annotation of human behavior. In Understanding Social
Behavior in Dyadic and Small Group Interactions&nbsp;(pp. 265-293).
PMLR.</p>
<p>Raman, C., Tan, S., &amp; Hung, H. (2020, October). A modular
approach for synchronized wireless multimodal multisensor data
acquisition in highly dynamic social settings. In Proceedings of the
28th ACM International Conference on Multimedia&nbsp;(pp. 3586-3594).</p>
<p>Raman, C., Vargas Quiros, J., Tan, S., Islam, A., Gedik, E., &amp;
Hung, H. (2022). ConfLab: A Data Collection Concept, Dataset, and
Benchmark for Machine Analysis of Free-Standing Social Interactions
in the Wild. Advances in Neural Information Processing Systems, 35,
23701-23715.</p>
<p>Raman, C., Tan, S., &amp; Hung, H. (2020, October). A modular
approach for synchronized wireless multimodal multisensor data
acquisition in highly dynamic social settings. In Proceedings of the
28th ACM International Conference on Multimedia&nbsp;(pp. 3586-3594).</p>
<h4><a name="h.ehxysfraymph"></a><a name="h.ibjqkwi20om9"></a>Talk
Title: F-formation Modelling and Behavioural Cue
Forecasting.<br/>
Speaker: &nbsp;Chirag Raman</h4>
<p>Abstract:</p>
<p>Associated Paper(s):</p>
<p>Raman, C., Hung, H., &amp; Loog, M. (2023, February). Social
processes: Self-supervised meta-learning over conversational groups
for forecasting nonverbal social cues. In Computer Vision–ECCV 2022
Workshops: Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part
III (pp. 639-659). Cham: Springer Nature Switzerland.</p>
<h4><a name="h.68svupq4mdnd"></a><a name="h.pj43nnn7mbbb"></a>Talk
Title: Estimating Conversational Enjoyment and Learning Multiple
Truths about Laughter<br/>
Speaker: &nbsp;Chirag Raman and Hayley
Hung</h4>
<p>Abstract:</p>
<p>Associated Paper(s):</p>
<p>Raman, C., Prabhu, N. R., &amp; Hung, H. (2023). Perceived
Conversation Quality in Spontaneous Interactions. IEEE Transactions
on Affective Computing</p>
<p>Vargas-Quiros, J., Cabrera-Quiros, L., Oertel, C., &amp; Hung, H.
(2022). Impact of annotation modality on label quality and model
performance in the automatic assessment of laughter in-the-wild.
arXiv preprint arXiv:2211.00794. To appear, IEEE Transactions on
Affective Computing</p>
<h4><a name="h.6ltyb6lvuyw2"></a><a name="h.jn4ivz8tdx76"></a><a name="h.5y5yk8iwr3u9"></a><a name="h.xq5n2el5kwma"></a>
Talk Title: The ConfFlow Application: Encouraging New Diverse
Collaborations by Helping Researchers Find Each Other at a
Conference<br/>
Speaker: &nbsp;Hayley Hung</h4>
<p>Abstract: We often find other collaborators by chance at a
conference or by looking for them specifically through their papers.
However, sometimes hidden potential social connections might exist
between different researchers that cannot be immediately observed
because the keywords we use might not always represent the entire
space of similar research interests.ConfFlow is an online application
that offers an alternative perspective on finding new research
connections. It is designed to help researchers find others at
conferences with complementary research interests for collaboration.
With ConfFlow we take a data-driven approach by using something
similar to the Toronto Paper Matching System (TPMS), used to identify
suitable reviewers for papers, to construct a similarity embedding
space for researchers to find other researchers. 
</p>
<p>Associated Paper(s):<br/>
H. Hung and E. Gedik, “Encouraging
Scientific Collaborations with ConfFlow 2021”, SIGMM Records,
<a href="https://www.google.com/url?q=https://records.sigmm.org/2022/04/20/encouraging-scientific-collaborations-with-confflow-2021/&amp;sa=D&amp;source=editors&amp;ust=1682333342512182&amp;usg=AOvVaw3teesEcRqKj4tVnLYroDT0">https://records.sigmm.org/2022/04/20/encouraging-scientific-collaborations-with-confflow-2021/</a>,
2022</p>
<p>H.Hung and E.Gedik, “Encouraging more Diverse Scientific
Collaborations with the ConfFlow application”, SIGMM Records,
<a href="https://www.google.com/url?q=https://records.sigmm.org/2021/06/10/encouraging-more-diverse-scientific-collaborations-with-the-confflow-application/&amp;sa=D&amp;source=editors&amp;ust=1682333342512728&amp;usg=AOvVaw2y7IrS67qNx_N-mIkixNYb">https://records.sigmm.org/2021/06/10/encouraging-more-diverse-scientific-collaborations-with-the-confflow-application/</a>,
2021</p>
<p>Gedik, E., &amp; Hung, H. (2020, October). ConfFlow: A Tool to
Encourage New Diverse Collaborations. In Proceedings of the 28th ACM
International Conference on Multimedia&nbsp;(pp. 4562-4564).</p>
<h2><a name="h.t8ene8slce3y"></a><a name="h.5htxyzvbch1o"></a><a name="h.r0r4rnwmcv0z"></a>
<br/>
<br/>
<br/>

</h2>
<p><a name="h.2ou0r5v8ze2o"></a><br/>
<br/>

</p>
</body>
</html>